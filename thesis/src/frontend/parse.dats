(* parsing: from string to an abstract syntax tree *)
(* this module is heavily based upon the lambdacalc example by Hongwei Xi *)
staload "shared/disj.sats"

staload "frontend/absyn.sats"
staload "frontend/parse.sats"

(* ****** ****** *)

staload "parcomb/posloc.sats"
staload "parcomb/tokenize.sats"

staload "parcomb/parcomb.sats"
staload _(*empty*) = "parcomb/parcomb.dats"

(* ****** ****** *)

(* concrete syntax
 * TODO: extend with syntax for numerals
 * TODO: extend with "let"?
 *
 * exp ::= id | exp_1 exp_2 | "\" id ":" ty "=>" exp | "(" exp ")"
 *   function application associates to the left:
 *   [f g x] means [(f g) x]
 *   FIXME: but we can't parse left-recursive grammars with recursive descent!
 * id ::= [_a-zA-Z][_a-zA-Z0-9]*
 *   identifiers are alphanumeric strings
 * ty ::= "int" | ty "->" ty | "(" ty ")"
 *   type constructor application associates to the right:
 *   [int -> int -> int] means [int -> (int -> int)]
 *
 * we also want precedence like this (highest to the left):
 * parens > application > abstraction
 *
 * both of these grammars are left-recursive. how do we transform them
 * into another form?
 * exp ::= foo | foo exp
 * foo ::= id | "\" id ":" ty "=>" exp | "(" exp ")"
 *
 * ty ::= bar | bar "->" ty
 * bar ::= "int" | "(" ty ")"
 * FIXME: can you prove that languages generated by these grammars
 * are the same as that of the grammars above?
 *
 * we will assume that the following subroutines exist:
 * [next] returns the next token of input or special EOF marker
 * [end] returns true if at the EOF
 * [consume] to advance our position in the input file by one token
 *    (not allowed at the EOF!)
 * [error] stops the parsing process and reports an error
 *)

infix (|| + 1) wth
infixl (&& + 2) <<; infixr (&& + 1) >>
postfix ^* ^+

(* ****** ****** *)

typedef P (a:t@ype) = parser_t (a, token)
typedef LP (a: t@ype) = lazy (parser_t (a, token))

val anytoken = any_parser<token> ()
val anyopttoken = anyopt_parser<token> ()

val LPAREN = anytoken \sat (lam (tok: token): bool =<fun>
  case+ tok.token_node of TOKsingleton '\(' => true | _ => false
)

val RPAREN = anytoken \sat (lam (tok: token): bool =<fun>
  case+ tok.token_node of TOKsingleton ')' => true | _ => false
)

val SEMICOLON = anytoken \sat (lam (tok: token): bool =<fun>
  case+ tok.token_node of TOKide ":" => true | _ => false
)

fn litident (name0: string): P token =
  anytoken \sat (lam (tok: token): bool =<cloref>
    case+ tok.token_node of TOKide name => name0 = name | _ => false
  )
// end of [litident]

val BACKSLASH = litident "\\"
val DOT = litident "."

val INT = litident "int"
val RARROW = litident "->"

(* ****** ****** *)

typedef TY0c = TY0 -<cloref> TY0
typedef EXP0c = EXP0 -<cloref> EXP0

fn isIdSymFst (c: char):<> bool = char_isalpha c || string_contains ("_'", c)
fn isIdSymRst (c: char):<> bool = isIdSymFst c || char_isdigit c
fn isKeyword (name: string):<> bool = false
fn isVar (name: string):<> bool = let
  fun loop {n,i:nat | i <= n} .<n-i>.
    (name: string n, i: size_t i):<> bool =
    if string_is_at_end (name, i) then true else let
      val c = $effmask_ref (name[i])
    in
      if isIdSymRst c then loop (name, i+1) else false
    end
in
  if isKeyword name then false else let
    val [n:int] name = string1_of_string name
  in
    if string_is_at_end (name, 0) then false else let
      val c0 = $effmask_ref (name[0])
    in
      if isIdSymFst c0 then loop (name, 1) else false
    end
  end
end

(* ****** ****** *)

(* initially, we have:
 * b = int          -- base types
 * t = b | (t -> t) -- all types
 *
 * but we want -> to associate to the right, and also
 * to have the outermost parentheses omitted
 * so int -> int is the same as (int -> int), and
 * int -> int -> int is the same as (int -> (int -> int)),
 * and also (int -> int) -> int -> int is the same as
 * ((int -> int) -> (int -> int))
 *
 * also, since we use recursive descent for parsing, we'd like
 * to convert our grammar to LL(k). we also annotate the grammar
 * with types.
 * ty_bas = int | ( ty ) : TY0
 * ty     = ty_bas ty_rst : TY0
 * ty_rst = (*empty*) | -> ty_rst : Option TY0
 * FIXME: prove that this grammar is the same as the one above?
 *)
val p_ty_int = (INT wth f_int) : P TY0 where {
  fn f_int (tok: token):<> TY0 = ty0_int (tok.token_loc)
}

val rec p_ty_bas : P TY0 = p_ty_int || (LPAREN >> lzeta lp_ty << LPAREN)

and lp_ty : LP TY0 = $delay (
  seq2wth_parser_fun (p_ty_bas, lzeta lp_ty_rst, f_cons)
) where {
  fn f_cons (t: TY0, tc: TY0c):<> TY0 = tc t
}

and lp_ty_rst : LP TY0c = $delay (
  seq2wth_parser_fun (RARROW >> p_ty_bas, lzeta lp_ty_rst, f) ||
  return (lam (t: TY0): TY0 =<cloref> t)
) where {
  fn f (t: TY0, tc: TY0c):<> TY0c =
    lam (t0) => let
      val loc = location_combine (t0.ty0_loc, t.ty0_loc)
    in
      tc (ty0_fun (loc, t0, t))
    end
}

(* ****** ****** *)
(*
 * what we have:
 * e = var | \var:type.e | e_1 e_2 | ( e )
 * but we want application to associate to the left and bind
 * stronger than anything else
 *
 * term_atm = var | ( term ) : EXP0
 * term     = \ var : ty . term | term_atm+ : EXP0
 *)

val p_var = (anytoken \sat pred): P token where {
  fn pred (tok: token):<> bool =
    case+ tok.token_node of TOKide name => isVar name | _ => false
}

val rec lp_term : LP EXP0 = $delay (
  (BACKSLASH >> seq3wth_parser_fun (p_var, SEMICOLON >> lzeta lp_ty << DOT
    , lzeta lp_term, f_lam)) ||
  seq2wth_parser_fun (lzeta lp_term_atm, lzeta lp_term_rst, f_app)
) where {
  fn f_lam (tok: token, typ: TY0, bod: EXP0):<> EXP0 = let
    val- TOKide name = tok.token_node
    val loc = location_combine (tok.token_loc, bod.exp0_loc)
  in
    exp0_lam (loc, name, typ, bod)
  end
  fn f_app (e: EXP0, ec: EXP0c):<> EXP0 = ec e
}

and lp_term_atm : LP EXP0 = $delay (
  p_var wth f_var || (LPAREN >> !lp_term << RPAREN)
) where {
  fn f_var (tok: token):<> EXP0 = let
    val- TOKide name = tok.token_node
  in
    exp0_var (tok.token_loc, name)
  end
}

and lp_term_rst : LP EXP0c = $delay (
  seq2wth_parser_fun (!lp_term_atm, lzeta lp_term_rst, f) ||
  return (lam (t: EXP0): EXP0 =<cloref> t)
) where {
  fn f (t: EXP0, tc: EXP0c):<> EXP0c =
    lam (t0) => let
      val loc = location_combine (t0.exp0_loc, t.exp0_loc)
    in
      tc (exp0_app (loc, t0, t))
    end
}

(* ****** ****** *)

dynload "parcomb/posloc.dats"
dynload "parcomb/parcomb.dats"
dynload "parcomb/tokenize.dats"

(* ****** ****** *)

fun {a:viewt@ype} parse_failure (tks: stream token, ncur: int, nmax: int)
  : disj_vt (string, a, 0) = let
  fun loop (tks: stream token, n: int): Option_vt token =
    case+ !tks of
    | stream_cons (tk, ts) =>
        if n > 0 then loop (tks, n-1) else Some_vt tk
    | stream_nil () => None_vt ()
  val otk = loop (tks, nmax - ncur)
in
  case+ otk of
  | ~Some_vt tk => InsLeft_vt "parsing failure" // TODO: show location
  | ~None_vt () => InsLeft_vt "parsing failure at the EOF"
end

(* ****** ****** *)

// making a lazy char stream out of a string buffer
//fn char_stream_make_strbuf {m,n:nat}
//  (sbf: &strbuf (m, n)):<> stream char = let

// FIXME: the only way we have here is to
// consume string buffer and get linear stream,
// so that's what we've got to do
// (we can then translate our linear stream
// into a non-linear one)
// FIXME: but we can't consume it since
// we use it for both repl and offline
// interpreter
// disregard all of the above;
// just try to write a function of the form
// strbuf -> list char

fn{a:t@ype} stream_of_list {n:nat}
  (xs: list (a, n)):<> stream a = $delay (loop xs) where {
  fun{a:t@ype} loop {n:nat} .<n>.
    (xs: list (a, n)):<> stream_con a =
    case+ xs of
    | list_nil () => stream_nil ()
    | list_cons (x, xs) => stream_cons (x, $delay (loop xs))
}

// I know this is quite pointless...
fn strbuf_to_list {m,n:nat}
  (sbf: &strbuf (m, n)):<> list (char, n) =
  loop (sbf, strbuf_length sbf, list_nil ()) where {
  fun loop {m,n:nat} {i:nat | 0 <= i; i <= n} .<i+1>.
    (sbf: &strbuf (m, n), i: size_t i, xs: list (char, n-i)):<> list (char, n) =
    if i >= 1 then let
      val i1 = i - 1
      val c = strbuf_get_char_at (sbf, i1)
      val xs = list_cons (c, xs)
    in
      loop (sbf, i1, xs)
    end else xs
}

implement parse_from_strbuf (sbf) = let
   // FIXME: I know this is grossly inefficient, but the deadline ...
   val tks0 = tokenstream_make_charstream (stream_of_list (strbuf_to_list sbf))
   var tks: stream token = tks0
   var ncur: int = 0 and nmax: int = 0
   val otrm = apply_parser (!lp_term, tks, ncur, nmax)
   // TODO: handle unconsumed tokens
in
  case+ otrm of
  | ~Some_vt trm => InsRight_vt trm
  | ~None_vt () => parse_failure (tks, ncur, nmax) : Disj_vt (string, EXP0)
end
